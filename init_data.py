#!/usr/bin/env python3
"""
ç”µå­ä¼šè®¡æ¡£æ¡ˆç³»ç»Ÿ - æ•°æ®åº“åˆå§‹åŒ–å’Œæµ‹è¯•æ•°æ®åˆ›å»ºè„šæœ¬
"""

import sys
import os
from datetime import datetime, timedelta, date
from werkzeug.security import generate_password_hash

# æ·»åŠ åº”ç”¨è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app import create_app, db
from models.user import User, Permission, Organization
from models.archive import ArchiveCategory, ElectronicArchive, ArchiveFile
from models.workflow import WorkflowRecord
# LifecycleRecord åœ¨ audit.py ä¸­å®šä¹‰
from models import audit
from models.audit import AuditLog
from utils.audit_logger import audit_logger

def create_initial_data():
    """åˆ›å»ºåˆå§‹æ•°æ®"""
    
    # 1. åˆ›å»ºæƒé™é…ç½®ï¼ˆä½¿ç”¨Permissionæ¨¡å‹ï¼‰
    permissions_data = [
        # æ¡£æ¡ˆç›¸å…³æƒé™
        {'user_id': 'admin_user', 'resource_type': 'archive', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'admin_user', 'resource_type': 'archive', 'operation': 'write', 'granted_by': 'admin_user'},
        {'user_id': 'admin_user', 'resource_type': 'archive', 'operation': 'delete', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'archive', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'archive', 'operation': 'write', 'granted_by': 'admin_user'},
        {'user_id': 'user1', 'resource_type': 'archive', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'auditor', 'resource_type': 'archive', 'operation': 'read', 'granted_by': 'admin_user'},
        
        # åˆ†ç±»ç®¡ç†æƒé™
        {'user_id': 'admin_user', 'resource_type': 'category', 'operation': 'admin', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'category', 'operation': 'admin', 'granted_by': 'admin_user'},
        
        # å·¥ä½œæµæƒé™
        {'user_id': 'admin_user', 'resource_type': 'workflow', 'operation': 'admin', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'workflow', 'operation': 'admin', 'granted_by': 'admin_user'},
        {'user_id': 'user1', 'resource_type': 'workflow', 'operation': 'read', 'granted_by': 'admin_user'},
        
        # ç»Ÿè®¡æƒé™
        {'user_id': 'admin_user', 'resource_type': 'statistics', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'statistics', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'user1', 'resource_type': 'statistics', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'auditor', 'resource_type': 'statistics', 'operation': 'read', 'granted_by': 'admin_user'},
        
        # å®¡è®¡æƒé™
        {'user_id': 'admin_user', 'resource_type': 'audit', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'auditor', 'resource_type': 'audit', 'operation': 'read', 'granted_by': 'admin_user'},
        
        # ç”¨æˆ·ç®¡ç†æƒé™
        {'user_id': 'admin_user', 'resource_type': 'user', 'operation': 'admin', 'granted_by': 'admin_user'},
        
        # ç”Ÿå‘½å‘¨æœŸæƒé™
        {'user_id': 'admin_user', 'resource_type': 'lifecycle', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'archiver_user', 'resource_type': 'lifecycle', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'user1', 'resource_type': 'lifecycle', 'operation': 'read', 'granted_by': 'admin_user'},
        {'user_id': 'auditor', 'resource_type': 'lifecycle', 'operation': 'read', 'granted_by': 'admin_user'}
    ]
    
    # 2. åˆ›å»ºç”¨æˆ·
    users_data = [
        {
            'username': 'admin',
            'email': 'admin@company.com',
            'password': 'admin123',
            'role': 'admin',
            'full_name': 'ç³»ç»Ÿç®¡ç†å‘˜',
            'department': 'ITéƒ¨é—¨'
        },
        {
            'username': 'archiver',
            'email': 'archiver@company.com', 
            'password': 'archive123',
            'role': 'archivist',
            'full_name': 'æ¡£æ¡ˆç®¡ç†å‘˜',
            'department': 'æ¡£æ¡ˆç®¡ç†éƒ¨'
        },
        {
            'username': 'user1',
            'email': 'user1@company.com',
            'password': 'user123',
            'role': 'user', 
            'full_name': 'å¼ ä¸‰',
            'department': 'è´¢åŠ¡éƒ¨'
        },
        {
            'username': 'auditor',
            'email': 'auditor@company.com',
            'password': 'audit123',
            'role': 'auditor',
            'full_name': 'å®¡è®¡å‘˜',
            'department': 'å®¡è®¡éƒ¨'
        }
    ]
    
    for user_data in users_data:
        user = User.query.filter_by(username=user_data['username']).first()
        if not user:
            user = User(
                username=user_data['username'],
                email=user_data['email'],
                role=user_data['role'],
                full_name=user_data['full_name'],
                department=user_data['department'],
                is_active=True
            )
            user.set_password(user_data['password'])
            db.session.add(user)
            print(f"åˆ›å»ºç”¨æˆ·: {user_data['username']}")
    
    db.session.commit()
    
    # 3. åˆ›å»ºæƒé™è®°å½•ï¼ˆåœ¨ç”¨æˆ·åˆ›å»ºåï¼‰
    for perm_data in permissions_data:
        # è·å–å®é™…çš„ç”¨æˆ·ID
        if perm_data['user_id'] == 'admin_user':
            user = User.query.filter_by(username='admin').first()
        elif perm_data['user_id'] == 'archiver_user':
            user = User.query.filter_by(username='archiver').first()
        elif perm_data['user_id'] == 'user1':
            user = User.query.filter_by(username='user1').first()
        elif perm_data['user_id'] == 'auditor':
            user = User.query.filter_by(username='auditor').first()
        else:
            continue
        
        if not user:
            continue
            
        # æ£€æŸ¥æƒé™æ˜¯å¦å·²å­˜åœ¨
        existing_perm = Permission.query.filter_by(
            user_id=user.id,
            resource_type=perm_data['resource_type'],
            operation=perm_data['operation']
        ).first()
        
        if not existing_perm:
            permission = Permission(
                user_id=user.id,
                resource_type=perm_data['resource_type'],
                operation=perm_data['operation'],
                granted_by=user.id,  # ä½¿ç”¨è‡ªå·±ä½œä¸ºæˆæƒè€…
                is_active=True
            )
            db.session.add(permission)
    
    db.session.commit()

def create_lifecycle_records():
    """åˆ›å»ºç”Ÿå‘½å‘¨æœŸè®°å½•"""
    print("æ­£åœ¨åˆ›å»ºç”Ÿå‘½å‘¨æœŸè®°å½•...")
    
    # è·å–æ‰€æœ‰æ¡£æ¡ˆ
    archives = ElectronicArchive.query.all()
    
    for archive in archives:
        # åˆ›å»ºè®°å½• - ä»auditæ¨¡å—å¯¼å…¥LifecycleRecord
        lifecycle_record = audit.LifecycleRecord(
            archive_id=archive.id,
            event_type='created',
            event_date=date.today(),
            description=f'æ¡£æ¡ˆ {archive.title} åˆ›å»º',
            operator_id=archive.created_by,
            event_metadata={'source': 'system'}
        )
        db.session.add(lifecycle_record)
        
        # æ¨¡æ‹Ÿä¸€äº›æ¡£æ¡ˆçš„å½’æ¡£æ“ä½œ
        if archive.status == 'archived':
            admin_user = User.query.filter_by(username='admin').first()
            lifecycle_record = audit.LifecycleRecord(
                archive_id=archive.id,
                event_type='archived',
                event_date=date.today() - timedelta(days=30),
                description=f'æ¡£æ¡ˆ {archive.title} å½’æ¡£',
                operator_id=admin_user.id if admin_user else archive.created_by,
                event_metadata={'reason': 'ä¿å­˜æœŸé™åˆ°æœŸ'}
            )
            db.session.add(lifecycle_record)
    
    db.session.commit()
    print(f"ç”Ÿå‘½å‘¨æœŸè®°å½•: {len(archives)} ä¸ªæ¡£æ¡ˆçš„è®°å½•å·²åˆ›å»º")

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    
    # è·å–ç”¨æˆ·ID
    admin_user = User.query.filter_by(username='admin').first()
    archiver_user = User.query.filter_by(username='archiver').first()
    normal_user = User.query.filter_by(username='user1').first()
    
    if not admin_user or not archiver_user:
        print("ç¼ºå°‘ç®¡ç†å‘˜ç”¨æˆ·ï¼Œè¯·å…ˆåˆ›å»ºåˆå§‹æ•°æ®")
        return
    
    # 1. åˆ›å»ºæ¡£æ¡ˆåˆ†ç±»
    categories_data = [
        {
            'code': 'FIN',
            'name': 'è´¢åŠ¡æ¡£æ¡ˆ',
            'description': 'è´¢åŠ¡ç›¸å…³æ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': '10_years'
        },
        {
            'code': 'ACC',
            'name': 'ä¼šè®¡å‡­è¯',
            'description': 'ä¼šè®¡å‡­è¯æ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': '30_years'
        },
        {
            'code': 'RPT',
            'name': 'è´¢åŠ¡æŠ¥è¡¨',
            'description': 'è´¢åŠ¡æŠ¥è¡¨æ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': '10_years'
        },
        {
            'code': 'HR',
            'name': 'äººäº‹æ¡£æ¡ˆ',
            'description': 'äººäº‹ç›¸å…³æ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': 'permanent'
        },
        {
            'code': 'EMP',
            'name': 'å‘˜å·¥æ¡£æ¡ˆ',
            'description': 'å‘˜å·¥ä¸ªäººæ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': 'permanent'
        },
        {
            'code': 'CON',
            'name': 'åˆåŒæ¡£æ¡ˆ',
            'description': 'åŠ³åŠ¨åˆåŒæ¡£æ¡ˆ',
            'parent_id': None,
            'retention_period': '10_years'
        }
    ]
    
    categories = {}
    for cat_data in categories_data:
        category = ArchiveCategory.query.filter_by(name=cat_data['name']).first()
        if not category:
            category = ArchiveCategory(
                code=cat_data['code'],
                name=cat_data['name'],
                description=cat_data['description'],
                parent_id=cat_data['parent_id'],
                retention_period=cat_data['retention_period'],
                is_active=True
            )
            db.session.add(category)
            categories[cat_data['name']] = category
            print(f"åˆ›å»ºåˆ†ç±»: {cat_data['name']}")
        else:
            categories[cat_data['name']] = category
    
    db.session.commit()
    print(f"å¯ç”¨åˆ†ç±»: {list(categories.keys())}")
    
    # 1.5 åˆ›å»ºé»˜è®¤ç»„ç»‡æœºæ„
    default_org = Organization.query.filter_by(code='DEFAULT').first()
    if not default_org:
        default_org = Organization(
            name='é»˜è®¤ç»„ç»‡',
            code='DEFAULT',
            description='ç³»ç»Ÿé»˜è®¤ç»„ç»‡æœºæ„'
        )
        db.session.add(default_org)
        db.session.commit()
        print(f"åˆ›å»ºé»˜è®¤ç»„ç»‡: {default_org.name}")
    
    # 2. åˆ›å»ºæµ‹è¯•æ¡£æ¡ˆ
    archives_data = [
        {
            'title': '2024å¹´ç¬¬ä¸€å­£åº¦è´¢åŠ¡æŠ¥è¡¨',
            'archive_no': 'FIN-2024-Q1-001',
            'category_id': 'categories["è´¢åŠ¡æ¡£æ¡ˆ"]',  # è·å–åˆ†ç±»ID
            'description': '2024å¹´ç¬¬ä¸€å­£åº¦çš„å®Œæ•´è´¢åŠ¡æŠ¥è¡¨',
            'confidentiality_level': 3,  # ç§˜å¯†çº§åˆ«
            'status': 'draft',
            'created_by': archiver_user.id,
            'retention_period': '10_years',
            'created_date': date.today(),
            'file_info': {
                'file_name': 'Q1_Financial_Report_2024.pdf',
                'file_size': 2048576,
                'file_type': 'pdf',
                'original_name': 'Q1_Financial_Report_2024.pdf'
            }
        },
        {
            'title': 'å‘˜å·¥åŠ³åŠ¨åˆåŒ-å¼ ä¸‰',
            'archive_no': 'HR-CT-001',
            'category_id': 'categories[\"åˆåŒæ¡£æ¡ˆ\"]',  # è·å–åˆ†ç±»ID
            'description': 'å¼ ä¸‰çš„åŠ³åŠ¨åˆåŒæ–‡ä»¶',
            'confidentiality_level': 4,  # æœºå¯†çº§åˆ«
            'status': 'draft',
            'created_by': archiver_user.id,
            'retention_period': '10_years',
            'created_date': date.today(),
            'file_info': {
                'file_name': 'ZhangSan_Contract.pdf',
                'file_size': 1024768,
                'file_type': 'pdf',
                'original_name': 'ZhangSan_Contract.pdf'
            }
        },
        {
            'title': '2024å¹´3æœˆä¼šè®¡å‡­è¯',
            'archive_no': 'ACC-2024-03-001',
            'category_id': 'categories[\"ä¼šè®¡å‡­è¯\"]',  # è·å–åˆ†ç±»ID
            'description': '2024å¹´3æœˆä»½çš„ä¼šè®¡å‡­è¯åˆé›†',
            'confidentiality_level': 2,  # å†…éƒ¨çº§åˆ«
            'status': 'draft',
            'created_by': archiver_user.id,
            'retention_period': '30_years',
            'created_date': date.today(),
            'file_info': {
                'file_name': 'March_2024_Accounting_Vouchers.zip',
                'file_size': 5242880,
                'file_type': 'zip',
                'original_name': 'March_2024_Accounting_Vouchers.zip'
            }
        },
        {
            'title': '2023å¹´åº¦å®¡è®¡æŠ¥å‘Š',
            'archive_no': 'AUD-2023-001',
            'category_id': 'categories[\"è´¢åŠ¡æ¡£æ¡ˆ\"]',  # è·å–åˆ†ç±»ID
            'description': '2023å¹´åº¦å…¬å¸å®¡è®¡æŠ¥å‘Š',
            'confidentiality_level': 5,  # ç»å¯†çº§åˆ«
            'status': 'archived',
            'created_by': admin_user.id,
            'retention_period': '10_years',
            'created_date': date(2023, 12, 31),
            'archive_date': date(2024, 1, 15),
            'file_info': {
                'file_name': 'Annual_Audit_Report_2023.pdf',
                'file_size': 4194304,
                'file_type': 'pdf',
                'original_name': 'Annual_Audit_Report_2023.pdf'
            }
        }
    ]
    
    for archive_data in archives_data:
        # è·å–å®é™…åˆ†ç±»ID
        category_id = None
        category_name = archive_data['category_id'].replace('categories["', '').replace('"]', '')
        if category_name in categories:
            category_id = categories[category_name].id
        
        archive = ElectronicArchive.query.filter_by(
            archive_no=archive_data['archive_no']
        ).first()
        if not archive:
            archive = ElectronicArchive(
                title=archive_data['title'],
                archive_no=archive_data['archive_no'],
                category_id=category_id,
                description=archive_data['description'],
                confidentiality_level=archive_data['confidentiality_level'],
                status=archive_data['status'],
                created_by=archive_data['created_by'],
                retention_period=archive_data['retention_period'],
                created_date=archive_data['created_date'],
                archive_date=archive_data.get('archive_date'),
                organization_id=default_org.id
            )
            db.session.add(archive)
            db.session.flush()  # ç«‹å³è·å– archive.id
            
            # åˆ›å»ºæ¡£æ¡ˆæ–‡ä»¶è®°å½•
            archive_file = ArchiveFile(
                archive_id=archive.id,
                file_name=archive_data['file_info']['file_name'],
                original_name=archive_data['file_info']['original_name'],
                file_path=f"/archives/{archive_data['file_info']['file_name']}",
                file_size=archive_data['file_info']['file_size'],
                file_type=archive_data['file_info']['file_type'],
                file_hash="abc123def456789",  # æ¨¡æ‹Ÿå“ˆå¸Œå€¼
                mime_type=f"application/{archive_data['file_info']['file_type']}",
                sort_order=1,
                is_main=True
            )
            db.session.add(archive_file)
            
            print(f"åˆ›å»ºæ¡£æ¡ˆ: {archive_data['title']}")
    
    db.session.commit()
    
    # 3. åˆ›å»ºç”Ÿå‘½å‘¨æœŸè®°å½•
    lifecycle_events = [
        {
            'archive_id': str(archive.id),
            'event_type': 'created',
            'event_date': date.today(),
            'description': f'æ¡£æ¡ˆ {archive.title} åˆ›å»º',
            'operator_id': str(admin_user.id if admin_user else archive.created_by),
            'metadata': {'source': 'system'}
        },
        {
            'archive_id': str(archive.id),
            'event_type': 'archived',
            'event_date': date.today(),
            'description': f'æ¡£æ¡ˆ {archive.title} å½’æ¡£',
            'operator_id': str(admin_user.id if admin_user else archive.created_by),
            'metadata': {'source': 'system'}
        }
    ]
    
    import json
    for event_data in lifecycle_events:
        lifecycle_record = audit.LifecycleRecord(
            archive_id=event_data['archive_id'],
            event_type=event_data['event_type'],
            event_date=event_data['event_date'],
            description=event_data['description'],
            operator_id=event_data['operator_id'],
            event_metadata=json.dumps(event_data['metadata']),
            created_at=datetime.utcnow() - timedelta(hours=1)
        )
        db.session.add(lifecycle_record)
    
    db.session.commit()
    
    # 4. åˆ›å»ºå·¥ä½œæµè®°å½•
    workflow_data = [
        {
            'title': 'å®¡æ ¸2024å¹´ç¬¬ä¸€å­£åº¦è´¢åŠ¡æŠ¥è¡¨',
            'workflow_type': 'review',
            'target_resource_type': 'archive',
            'target_resource_id': 1,
            'description': 'éœ€è¦å¯¹Q1è´¢åŠ¡æŠ¥è¡¨è¿›è¡Œå®¡æ ¸',
            'initiator_id': str(normal_user.id),
            'status': 'pending',
            'priority': 'high',
            'config': {'auto_approve': False}
        },
        {
            'title': 'å®¡æ‰¹å‘˜å·¥è½¬æ­£ç”³è¯·',
            'workflow_type': 'approval',
            'target_resource_type': 'user',
            'target_resource_id': 3,
            'description': 'å¼ ä¸‰çš„è½¬æ­£ç”³è¯·å®¡æ‰¹',
            'initiator_id': str(admin_user.id),
            'status': 'pending',
            'priority': 'normal',
            'config': {'auto_approve': False}
        }
    ]
    
    import json
    for wf_data in workflow_data:
        workflow = WorkflowRecord.query.filter_by(title=wf_data['title']).first()
        if not workflow:
            workflow = WorkflowRecord(
                title=wf_data['title'],
                workflow_type=wf_data['workflow_type'],
                target_resource_type=wf_data['target_resource_type'],
                target_resource_id=wf_data['target_resource_id'],
                description=wf_data['description'],
                initiator_id=wf_data['initiator_id'],
                status=wf_data['status'],
                priority=wf_data['priority'],
                due_date=datetime.utcnow().date() + timedelta(days=7),
                workflow_config=json.dumps(wf_data['config'])
            )
            db.session.add(workflow)
            print(f"åˆ›å»ºå·¥ä½œæµ: {wf_data['title']}")
    
    db.session.commit()
    
    # 5. åˆ›å»ºå®¡è®¡æ—¥å¿—
    audit_events = [
        {
            'user_id': str(archiver_user.id),
            'operation_type': 'create',
            'resource_type': 'archive',
            'resource_id': str(archive.id),
            'operation_details': {'archive_number': 'FIN-2024-Q1-001', 'title': archive.title},
            'ip_address': '192.168.1.100',
            'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
            'result': 'success'
        },
        {
            'user_id': str(admin_user.id),
            'operation_type': 'login',
            'resource_type': 'user',
            'resource_id': str(admin_user.id),
            'operation_details': {'login_time': datetime.utcnow().isoformat()},
            'ip_address': '192.168.1.100',
            'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
            'result': 'success'
        }
    ]
    
    for audit_data in audit_events:
        audit_log = AuditLog(
            user_id=audit_data['user_id'],
            operation_type=audit_data['operation_type'],
            resource_type=audit_data['resource_type'],
            resource_id=audit_data['resource_id'],
            operation_details=audit_data['operation_details'],
            ip_address=audit_data['ip_address'],
            user_agent=audit_data['user_agent'],
            result=audit_data['result'],
            created_at=datetime.utcnow() - timedelta(hours=2)
        )
        db.session.add(audit_log)
    
    db.session.commit()
    
    print("\nâœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ!")
    print("ğŸ“Š åˆ›å»ºäº†ä»¥ä¸‹æ•°æ®:")
    print(f"   - æƒé™: {Permission.query.count()} ä¸ª")
    print(f"   - ç”¨æˆ·: {User.query.count()} ä¸ª")
    print(f"   - åˆ†ç±»: {ArchiveCategory.query.count()} ä¸ª")
    print(f"   - æ¡£æ¡ˆ: {ElectronicArchive.query.count()} ä¸ª")
    print(f"   - æ–‡ä»¶: {ArchiveFile.query.count()} ä¸ª")
    print(f"   - ç”Ÿå‘½å‘¨æœŸè®°å½•: {audit.LifecycleRecord.query.count()} ä¸ª")
    print(f"   - å·¥ä½œæµ: {WorkflowRecord.query.count()} ä¸ª")
    print(f"   - å®¡è®¡æ—¥å¿—: {AuditLog.query.count()} ä¸ª")

def main():
    """ä¸»å‡½æ•°"""
    app = create_app()
    
    with app.app_context():
        print("ğŸš€ å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“...")
        
        try:
            # åˆ›å»ºè¡¨
            db.create_all()
            print("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
            
            # åˆ›å»ºåˆå§‹æ•°æ®
            create_initial_data()
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            create_test_data()
            
            print("\nğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")
            print("\nğŸ” æµ‹è¯•è´¦æˆ·ä¿¡æ¯:")
            print("   ç®¡ç†å‘˜: admin / admin123")
            print("   æ¡£æ¡ˆå‘˜: archiver / archive123") 
            print("   æ™®é€šç”¨æˆ·: user1 / user123")
            print("   å®¡è®¡å‘˜: auditor / audit123")
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            db.session.rollback()

if __name__ == '__main__':
    main()